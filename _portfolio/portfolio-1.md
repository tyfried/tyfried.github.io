---
title: "Sunesiary"
excerpt: "A prototype for aggregating and refining contextual information.<br/><img src='/images/sunesiary.png'>"
collection: portfolio
permalink: /portfolio/sunesiary
---

<img src='/images/sunesiary.png'><br/>

Sunesiary adapts a wiki towards a novel model for aggregating and refining contextual information.  The goal is to provide a neutral, trusted repository of context for helping to break down and understand controversial topics.  I have developed a [proposal](http://tyfried.github.io/files/discourse.pdf) for future study of this work in graduate school.  A proof-of-concept is available at [www.sunesiary.org](https://www.sunesiary.org).

## Motivation

### Mistakes

The saying goes: *we learn from our mistakes*.  Yet modern online communities of inquiry seem to focus more on broadcasting insights, and less the mistakes, bad ideas, and outliers that directly led to them.  On the one hand, this makes sense: if your goal as a community is to accumulate knowledge as efficiently as possible, then presenting tangents will necessarily distract the audience away from your message.  But if your goal is to accumulate **understanding**, then these missteps require a mechanism for greater visibility.


### Discourse

The state of public discourse is unhealthy at best.  Some examples:
* Journalism is under siege, both [figuratively](https://issues.org/journalism-under-attack/) and [literally](https://www.nytimes.com/2018/10/11/world/americas/journalists-killed.html).
* A [recent analysis](https://www.nature.com/articles/d41586-018-02934-x) of how true and false news spreads on Twitter found that not only did falsehoods spread more widely and at a faster rate than the truth, but that it was humans, not robots, who were more likely to spread it.
* A nontrivial percentage of peer-reviewed, quantitative research findings appear to be [false as well](https://blog.communitydata.cc/a-proposal-to-mitigate-false-discovery-in-cscw-research/).


<!-- ; it is also increasingly shifting towards mediums which do not support [rational argument](https://en.wikipedia.org/wiki/Amusing_Ourselves_to_Death) -->

<!-- [^1]: Credit to the Community Data Science Collective, I first learned about this issue on their [blog](https://blog.communitydata.cc/a-proposal-to-mitigate-false-discovery-in-cscw-research/). -->

In each of these crises, I see an opportunity for an unbiased collection of contextual information to make a difference: for the news industry, a vehicle to showcase quality journalism; for social media, a home for more nuanced discussions in search of truth; and for academia, a place for the digestion of intricate concepts. What I am suggesting is not a replacement for these mediums, but rather a mechanism for placing them in their proper context.

## Model
I believe that all contextual information can roughly be categorized as
* **writings**, the creative work that we produce to try to make sense of the world;
* **statements**, the subsequent claims we derive from these writings; and
* **questions**, the unknowns arising when two or more of these statements directly contradict.

These three categories reinforce each other: writings argue towards particular statements, contradicting statements suggest a particular question, and unanswered questions inspire new writings.  Together, they form a cycle (see above) which captures how complex ideas evolve within communities of inquiry.

## Sunesiary

[Sunesiary](https://www.sunesiary.org) integrates these insights into a project that allows a dedicated group of contributors to accumulate understanding concerning topics of interest.  If you are interested in learning more, please shoot me an email at [sunesiary@gmail.com](mailto:sunesiary@gmail.com).
